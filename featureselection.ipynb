{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def creating_dataset():\n",
    "    df = pd.read_csv('dataset/datasetcleaned.csv', index_col=[0])\n",
    "    X = df.drop('DEP_DEL15', axis=1).drop('MONTH',axis=1).drop(\"LONGITUDE\",axis=1).drop(\"LATITUDE\",axis=1)\n",
    "    y = df['DEP_DEL15']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,shuffle=True)\n",
    "    x_train,x_test = scaleNorm(x_train,x_test)\n",
    "    return x_train,x_test,y_train,y_test\n",
    "\n",
    "def redoSplit(x,y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42,shuffle=True)\n",
    "    return x_train,x_test,y_train,y_test\n",
    "\n",
    "def balancing_dataset(x_train,y_train,drop_per):\n",
    "    idx = np.where(y_train == 0)[0]\n",
    "    x_train = (x_train.drop(x_train.index[idx[:int(len(idx)*drop_per)]]))\n",
    "    y_train = (y_train.drop(y_train.index[idx[:int(len(idx)*drop_per)]]))\n",
    "    return x_train,y_train\n",
    "\n",
    "def standardize(x):\n",
    "    x = x.to_numpy()\n",
    "    x = (x- np.min(x,axis=0))/np.max(x,axis=0)\n",
    "    return x\n",
    "\n",
    "def scaleNorm(X_train,X_test):\n",
    "    X_train = standardize(X_train)\n",
    "    X_test = standardize(X_test)\n",
    "    return pd.DataFrame(X_train),pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Current best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestFittingMethod(x,y):\n",
    "    xgb_model = xgb.XGBClassifier(learning_rate=0.1,\n",
    "                                  max_depth=10,\n",
    "                                  eval_metric='logloss')\n",
    "    xgb_model.fit(x, y)\n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,x_real_test,Y,y_real_test = creating_dataset()\n",
    "cols = pd.read_csv('dataset/datasetcleaned.csv', index_col=[0]).drop('DEP_DEL15', axis=1).drop('MONTH',axis=1).drop(\"LONGITUDE\",axis=1).drop(\"LATITUDE\",axis=1).columns\n",
    "x_real_train,x_test,y_real_train,y_test = redoSplit(X,Y)\n",
    "x,y = balancing_dataset(x_real_train,y_real_train,0.8)\n",
    "x_train,x_test,y_train,y_test = redoSplit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Diego/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66199705 0.3376075 ]\n",
      " [0.33800295 0.6623925 ]]\n",
      "acc non delay: 0.6619970519189824 acc delay: 0.6623925021885781\n"
     ]
    }
   ],
   "source": [
    "X,x_real_test,y,y_real_test = creating_dataset()\n",
    "cols = pd.read_csv('dataset/datasetcleaned.csv', index_col=[0]).drop('DEP_DEL15', axis=1).drop('MONTH',axis=1).drop(\"LONGITUDE\",axis=1).drop(\"LATITUDE\",axis=1).columns\n",
    "x_train,x_test,y_train,y_test = redoSplit(X,y)\n",
    "x_train,y_train = balancing_dataset(x_train,y_train,0.8)\n",
    "clf = bestFittingMethod(x_train,y_train)\n",
    "y_pred_test = clf.predict(x_test)\n",
    "y_pred_test = clf.predict(x_test)\n",
    "cm_test = confusion_matrix(y_pred_test,y_test.to_numpy())\n",
    "\n",
    "n_cm_test = cm_test/np.sum(cm_test,axis=0)\n",
    "print(n_cm_test)\n",
    "print(\"acc non delay:\",n_cm_test[0,0],\"acc delay:\",n_cm_test[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delay_acc = []\n",
    "not_delay_acc = []\n",
    "for i in range(1,10):\n",
    "    x_train,x_test,y_train,y_test = redoSplit(X,y)\n",
    "    x_train,y_train = balancing_dataset(x_train,y_train,i/10)\n",
    "    clf = bestFittingMethod(x_train,y_train)\n",
    "    y_pred_test = clf.predict(x_test)\n",
    "    y_pred_test = clf.predict(x_test)\n",
    "    cm_test = confusion_matrix(y_pred_test,y_test.to_numpy())\n",
    "    print(cm_test)\n",
    "    n_cm_test = cm_test /np.sum(cm_test,axis=0)\n",
    "    print(\"acc non delay:\",n_cm_test[0,0],\"acc delay:\",n_cm_test[1,1])\n",
    "    delay_acc.append(n_cm_test[0,0])\n",
    "    not_delay_acc.append(n_cm_test[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,10)*0.1,delay_acc,label=\"delay\")\n",
    "plt.plot(np.arange(1,10)*0.1,not_delay_acc,label=\"not delayed\")\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,1)\n",
    "plt.title(\"Accuracy of the model with respect of the percentage of dropped 'delayed' instances\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def computingFscoresAccuracies(verbose = False):\n",
    "    f_scores_train = []\n",
    "    f_scores_test = []\n",
    "    delay_hits = []\n",
    "    nondelay_hits = []\n",
    "    for k_f in tqdm(range(1,15)):\n",
    "        x_train,x_test,y_train,y_test = redoSplit(X,y)\n",
    "        x_train,y_train = balancing_dataset(x_train,y_train,0.8)\n",
    "        Kbest_f = SelectKBest(f_classif, k=k_f).fit(x_train, y_train)\n",
    "        Xf = Kbest_f.transform(x_train)\n",
    "        Xf_test = Kbest_f.transform(x_test)\n",
    "        #fitting\n",
    "        clf = bestFittingMethod(Xf,y_train)\n",
    "        #accuracy\n",
    "        #train\n",
    "        y_pred_train = clf.predict(Xf)\n",
    "        Train_f_score = f1_score(y_train.to_numpy(),y_pred_train)\n",
    "        f_scores_train.append(Train_f_score)\n",
    "        #test\n",
    "        y_pred_test = clf.predict(Xf_test)\n",
    "        f_score_test = f1_score(y_test.to_numpy(),y_pred_test)\n",
    "        f_scores_test.append(f_score_test)\n",
    "        cm_test = confusion_matrix(y_pred_test,y_test.to_numpy())\n",
    "        n_cm_test = cm_test /np.sum(cm_test,axis=0)\n",
    "        delay_hits.append(n_cm_test[0,0])\n",
    "        nondelay_hits.append(n_cm_test[1,1])\n",
    "        if verbose: \n",
    "            train_acc,t_acc = clf.score(Xf, y_train), clf.score(Xf_test, y_test)\n",
    "            cm = confusion_matrix(y_pred_train,y_train.to_numpy())\n",
    "            print(f\"---k={k_f}-----------------------------------------------------\")\n",
    "            print(\"Train accuracy\",train_acc)\n",
    "            print(\"Test accuracy\",t_acc)\n",
    "            print(\"confusion matrix train \\n\",cm /np.sum(cm,axis=0))\n",
    "            print(\"train score:\",clf.score(Xf,y_train))\n",
    "            print(\"train f-score:\",Train_f_score)\n",
    "            print(\"confusion matrix test \\n\",cm_test /np.sum(cm_test,axis=0))\n",
    "            print(\"test score:\",clf.score(Xf_test,y_test))\n",
    "            print(\"test f-score:\",f_score_test)\n",
    "    return f_scores_train,f_scores_test,delay_hits,nondelay_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_scores_train,f_scores_test,df,ndf = computingFscoresAccuracies(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,15),df,label=\"delay accuracy\")\n",
    "plt.plot(np.arange(1,15),ndf,label=\"not delayed accuracy\")\n",
    "plt.xlabel(\"Value of k\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_col = dict(enumerate(cols))\n",
    "scores,p_values = f_classif(x_train,y_train)\n",
    "k = len(scores)\n",
    "for i in reversed(range(k)):\n",
    "    print(num_to_col[np.argsort(scores)[-k:][i]],np.log(np.sort(scores)[-k:][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## $\\chi^2$ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computingChi2scoresAccuracies(verbose = False):\n",
    "    #X need to be non negative to apply this method\n",
    "    chi2_scores_train = []\n",
    "    chi2_scores_test = []\n",
    "    delay_hits = []\n",
    "    nondelay_hits = []\n",
    "    for k in tqdm(range(1,15)):\n",
    "        x_train,x_test,y_train,y_test = redoSplit(X,y)\n",
    "        x_train,y_train = balancing_dataset(x_train,y_train,0.8)\n",
    "        x_chi2 = x_train.copy()\n",
    "        x_chi2_test = x_test.copy()\n",
    "        Kbest_chi2 = SelectKBest(chi2, k=k).fit(x_chi2, y_train)\n",
    "        Xchi2 = Kbest_chi2.transform(x_chi2)\n",
    "        XTchi2 = Kbest_chi2.transform(x_chi2_test)\n",
    "        #fitting\n",
    "        clf = bestFittingMethod(Xchi2,y_train)\n",
    "        #accuracy\n",
    "        #train\n",
    "        y_pred_train = clf.predict(Xchi2)\n",
    "        Train_chi2_score = f1_score(y_train.to_numpy(),y_pred_train)\n",
    "        chi2_scores_train.append(Train_chi2_score)\n",
    "        #test\n",
    "        y_pred_test = clf.predict(XTchi2)\n",
    "        Test_chi2_score = f1_score(y_test.to_numpy(),y_pred_test)\n",
    "        chi2_scores_test.append(Test_chi2_score)\n",
    "        cm_test = confusion_matrix(y_pred_test,y_test.to_numpy())\n",
    "        n_cm_test = cm_test /np.sum(cm_test,axis=0)\n",
    "        delay_hits.append(n_cm_test[0,0])\n",
    "        nondelay_hits.append(n_cm_test[1,1])\n",
    "        if verbose: \n",
    "            cm = confusion_matrix(y_pred_train,y_train.to_numpy())\n",
    "            cm_test = confusion_matrix(y_pred_test,y_test.to_numpy())\n",
    "            print(f\"---k={k_f}-----------------------------------------------------\")\n",
    "            print(\"confusion matrix train \\n\",cm /np.sum(cm,axis=0))\n",
    "            print(\"train f-score:\",Train_f_score)\n",
    "            print(\"confusion matrix test \\n\",cm_test /np.cm_test(cm,axis=0))\n",
    "            print(\"test chi2-score:\",Test_chi2_score)\n",
    "    return chi2_scores_train,chi2_scores_test,delay_hits,nondelay_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chi2_scores_train,chi2_scores_test,d_chi2,nd_chi2 = computingChi2scoresAccuracies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,15),d_chi2,label=\"delay accuracy\")\n",
    "plt.plot(np.arange(1,15),nd_chi2,label=\"not delayed accuracy\")\n",
    "plt.xlabel(\"Value of k\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,p_values = chi2(x_train,y_train)\n",
    "k = len(scores)\n",
    "print(\"printing log scores\")\n",
    "for i in reversed(range(k)):\n",
    "    print(cols[np.argsort(scores)[-k:][i]],np.log(np.sort(scores)[-k:][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computingPCAscoresAccuracies(verbose = False):\n",
    "    scores_train = []\n",
    "    scores_test = []\n",
    "    delay_hits = []\n",
    "    nondelay_hits = []\n",
    "    for k in tqdm(range(1,15)):\n",
    "        x_train,x_test,y_train,y_test = redoSplit(X,y)\n",
    "        x_train,y_train = balancing_dataset(x_train,y_train,0.8)\n",
    "        #transforming\n",
    "        pca = PCA(n_components=k)\n",
    "        pca.fit(x_train)\n",
    "        Xpca = pca.transform(x_train)\n",
    "        Xpca -= np.min(Xpca,axis=0);Xpca /= np.max(Xpca,axis=0)\n",
    "        Xtestpca = pca.fit_transform(x_test)\n",
    "        Xtestpca -= np.min(Xtestpca,axis=0);Xtestpca /= np.max(Xtestpca,axis=0)\n",
    "        #fitting\n",
    "        clf = bestFittingMethod(Xpca,y_train)\n",
    "        #accuracy\n",
    "        #train\n",
    "        y_pred_train = clf.predict(Xpca)\n",
    "        score_train = clf.score(Xpca,y_train.to_numpy())\n",
    "        scores_train.append(score_train)\n",
    "        #test\n",
    "        y_pred_test = clf.predict(Xtestpca)\n",
    "        score_test = clf.score(Xtestpca,y_test.to_numpy())\n",
    "        scores_test.append(score_test)\n",
    "        cm_test = confusion_matrix(y_pred_test,y_test.to_numpy())\n",
    "        n_cm_test = cm_test /np.sum(cm_test,axis=0)\n",
    "        delay_hits.append(n_cm_test[0,0])\n",
    "        nondelay_hits.append(n_cm_test[1,1])\n",
    "        if verbose: \n",
    "            cm = confusion_matrix(y_pred_train,y_train.to_numpy())\n",
    "            cm_test = confusion_matrix(y_pred_test,y_test.to_numpy())\n",
    "            print(f\"---k={k}-----------------------------------------------------\")\n",
    "            print(\"confusion matrix train \\n\",cm /np.sum(cm,axis=0))\n",
    "            print(\"train score:\",score_train)\n",
    "            print(\"confusion matrix test \\n\",cm_test /np.sum(cm_test,axis=0))\n",
    "            print(\"test score:\",score_test)\n",
    "        clf = None\n",
    "    return scores_train,scores_test,delay_hits,nondelay_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcaScoresTrain,pcaScoresTest,d_pca,nd_pca = computingPCAscoresAccuracies(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,15),d_pca,label=\"delay accuracy\")\n",
    "plt.plot(np.arange(1,15),nd_pca,label=\"not delayed accuracy\")\n",
    "plt.xlabel(\"Value of k\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
