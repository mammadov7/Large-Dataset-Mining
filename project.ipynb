{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "import time\n",
    "import pickle\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dataset():\n",
    "    df = pd.read_csv('dataset/datasetcleaned.csv', index_col=[0])\n",
    "    X = df.drop('DEP_DEL15', axis=1).drop('MONTH',axis=1).drop(\"LONGITUDE\",axis=1).drop(\"LATITUDE\",axis=1)\n",
    "    y = df['DEP_DEL15']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,shuffle=True)\n",
    "    x_train,x_test = scaleNorm(x_train,x_test)\n",
    "    return x_train,x_test,y_train,y_test\n",
    "\n",
    "def redoSplit(x,y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42,shuffle=True)\n",
    "    return x_train,x_test,y_train,y_test\n",
    "\n",
    "def balancing_dataset(x_train,y_train,drop_per):\n",
    "    idx = np.where(y_train == 0)[0]\n",
    "    x_train = (x_train.drop(x_train.index[idx[:int(len(idx)*drop_per)]]))\n",
    "    y_train = (y_train.drop(y_train.index[idx[:int(len(idx)*drop_per)]]))\n",
    "    return x_train,y_train\n",
    "\n",
    "def standardize(x):\n",
    "    x = x.to_numpy()\n",
    "    x = (x- np.min(x,axis=0))/np.max(x,axis=0)\n",
    "    return x\n",
    "\n",
    "def scaleNorm(X_train,X_test):\n",
    "    X_train = standardize(X_train)\n",
    "    X_test = standardize(X_test)\n",
    "    return pd.DataFrame(X_train),pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X,x_real_test,Y,y_real_test = creating_dataset()\n",
    "cols = pd.read_csv('dataset/datasetcleaned.csv', index_col=[0]).drop('DEP_DEL15', axis=1).drop('MONTH',axis=1).drop(\"LONGITUDE\",axis=1).drop(\"LATITUDE\",axis=1).columns\n",
    "x_real_train,x_test,y_real_train,y_test = redoSplit(X,Y)\n",
    "x,y = balancing_dataset(x_real_train,y_real_train,0.8)\n",
    "x_train,x_test,y_train,y_test = redoSplit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48636716 0.47966301]\n",
      " [0.51363284 0.52033699]]\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "y_pred = np.random.randint(0,2,y_train.shape)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(cm /np.sum(cm,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 ... 1 5 5]\n"
     ]
    }
   ],
   "source": [
    "weights = y_train.to_numpy()*4 + 1\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:06:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[00:06:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[0.84515874 0.33462282]\n",
      " [0.15484126 0.66537718]]\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(weight=weights)\n",
    "clf.fit(x_real_train, y_real_train)\n",
    "train_acc,t_acc = clf.score(x_real_train, y_real_train), clf.score(x_real_test, y_real_test)\n",
    "y_hat = clf.predict(x_real_test)\n",
    "cm = confusion_matrix(y_real_test, y_hat)\n",
    "print(cm /np.sum(cm,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Diego/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.648341   0.33749322]\n",
      " [0.351659   0.66250678]]\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(learning_rate=0.1,\n",
    "                                  max_depth=10,\n",
    "                                  eval_metric='logloss')\n",
    "xgb_model.fit(x_train,y_train)\n",
    "y_pred_test = xgb_model.predict(x_test)\n",
    "cm_test = confusion_matrix(y_pred_test,y_test.to_numpy())\n",
    "print(cm_test /np.sum(cm_test,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Train accuracy\", clf.score(x_train, y_train))\n",
    "print(\"Test accuracy\", clf.score(x_test, y_test))\n",
    "y_hat = clf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "print(cm /np.sum(cm,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier()\n",
    "clf.fit(x_train, y_train, verbose=False)\n",
    "print(\"Train accuracy\", clf.score(x_train, y_train))\n",
    "print(\"Test accuracy\", clf.score(x_test, y_test))\n",
    "y_hat = clf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "print(cm /np.sum(cm,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOG_DIR = f\"{int(time.time())}\"\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=LOG_DIR)\n",
    "\n",
    "def build_model(hp):  # random search passes this hyperparameter() object \n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(Dense(hp.Int('input_units',min_value=50, max_value=200, step=50), \n",
    "                    input_shape=x_train.shape[1:],\n",
    "                    activation='relu'))\n",
    "\n",
    "    model.add( Dropout(hp.Float('dropout_rate',\n",
    "                                    min_value=0.0,\n",
    "                                    max_value=0.5,\n",
    "                                    step=0.1) ) )\n",
    "    \n",
    "    for i in range(hp.Int('n_layers', 1, 2)):  # adding variation of layers.\n",
    "        model.add(Dense(hp.Int(f'layer_{i}_units',\n",
    "                                min_value=10,\n",
    "                                max_value=150,\n",
    "                                step=30), \n",
    "                                activation='relu'))\n",
    "    \n",
    "        model.add( Dropout(hp.Float(f'dropout_{i}_rate',\n",
    "                                    min_value=0.0,\n",
    "                                    max_value=0.5,\n",
    "                                    step=0.1) ) )\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics =['accuracy'])\n",
    "              \n",
    "    return model\n",
    "                  \n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='accuracy',\n",
    "    max_trials=10,  # how many variations on model?\n",
    "    executions_per_trial=1) # how many trials per variation? (same model could perform differently)\n",
    "\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train,\n",
    "             y=y_train,\n",
    "             epochs=5,\n",
    "             batch_size=64)\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model():  # random search passes this hyperparameter() object \n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(Dense(200, input_shape=x_train.shape[1:], activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add( Dropout( 0.1 ) )\n",
    "    model.add(Dense(70, activation='relu'))\n",
    "    model.add( Dropout( 0.4 ) )\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics =['accuracy'])\n",
    "              \n",
    "    return model\n",
    "                  \n",
    "\n",
    "model = build_model()\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "reducer = tf.keras.callbacks.ReduceLROnPlateau( monitor='loss', factor=0.5, patience=3, verbose=1, mode='min')\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train, callbacks=[early_stopping, reducer], batch_size=256,verbose=1,epochs=1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict_classes(x_real_test)\n",
    "# y_test\n",
    "print(\"Test accuracy\", sklearn.metrics.accuracy_score(y_real_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict(x_real_test)\n",
    "cm = confusion_matrix(y_real_test, y_hat)\n",
    "cm /np.sum(cm,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Recall Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "train_precision, train_recall, _ = precision_recall_curve(y_train, y_train_pred)\n",
    "train_ap = average_precision_score(y_train, y_train_pred)\n",
    "y_test_pred = model.predict(x_real_test)\n",
    "test_precision, test_recall, _ = precision_recall_curve(y_real_test, y_test_pred)\n",
    "test_ap = average_precision_score(y_real_test, y_test_pred)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "axs = plt.subplot(2,2,1)\n",
    "axs.set_title('Train Precision Recall Curve')\n",
    "axs.set_xlabel('Recall')\n",
    "axs.set_ylabel('Precission')\n",
    "axs.plot(train_recall, train_precision, label = 'AP = {:.4f}'.format(train_ap))\n",
    "axs.legend()\n",
    "\n",
    "axs = plt.subplot(2,2,2)\n",
    "axs.set_title('Test Precision Recall Curve')\n",
    "axs.set_xlabel('Recall')\n",
    "axs.set_ylabel('Precission')\n",
    "axs.plot(test_recall, test_precision, label = 'AP = {:.4f}'.format(test_ap))\n",
    "axs.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fpr, train_tpr, _ = roc_curve(y_train, y_train_pred)\n",
    "train_auc = auc(train_fpr, train_tpr)\n",
    "\n",
    "test_fpr, test_tpr, _ = roc_curve(y_real_test, y_test_pred)\n",
    "test_auc = auc(test_fpr, test_tpr)\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "axs = plt.subplot(2,2,1)\n",
    "axs.set_title('Train ROC Curve')\n",
    "axs.set_xlabel('False Positive Rate')\n",
    "axs.set_ylabel('True Positive Rate')\n",
    "axs.plot(train_fpr, train_tpr, label = 'AUC = {:.4f}'.format(train_auc))\n",
    "axs.legend()\n",
    "\n",
    "axs = plt.subplot(2,2,2)\n",
    "axs.set_title('Test ROC Curve')\n",
    "axs.set_xlabel('False Positive Rate')\n",
    "axs.set_ylabel('True Positive Rate')\n",
    "axs.plot(test_fpr, test_tpr, label = 'AUC = {:.4f}'.format(test_auc))\n",
    "axs.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_acc = []\n",
    "# test_acc = []\n",
    "# X = df.drop('DEP_DEL15', axis=1)\n",
    "# y = df['DEP_DEL15']\n",
    "# X_tmp, X_test, y_tmp, y_test = train_test_split(X, y, test_size=0.20, random_state=42,shuffle=True)\n",
    "# for i in range(1,9):\n",
    "#     print(\"curr percentage\",i/10)\n",
    "#     X_train,X_val,y_train,y_val = train_test_split(X_tmp, y_tmp, test_size=0.33, random_state=42,shuffle=True)\n",
    "#     idx = np.where(y_train == 0)[0]\n",
    "#     drop_per = int(len(idx)*i/10)\n",
    "#     X_train = X_train.drop(X_train.index[idx[:drop_per]])\n",
    "#     y_train = y_train.drop(y_train.index[idx[:drop_per]])\n",
    "\n",
    "#     clf = xgb.XGBClassifier()\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     train_acc,t_acc = clf.score(X_train, y_train), clf.score(X_val, y_val)\n",
    "#     tr_acc.append(train_acc)\n",
    "#     test_acc.append(t_acc)\n",
    "#     print(\"Train accuracy\",train_acc)\n",
    "#     print(\"Test accuracy\",t_acc)\n",
    "#     y_hat = clf.predict(X_val)\n",
    "#     cm = confusion_matrix(y_val, y_hat)\n",
    "#     print(cm /np.sum(cm,axis=0))\n",
    "    \n",
    "# y_train_pred = clf.predict_proba(X_train)\n",
    "# y_test_pred = clf.predict_proba(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
